## 基础设施(2)

### 用调试发现问题

理解指令的执行过程之后, 添加各种指令更多的是工程实现. 工程实现难免会碰到bug, 实现不正确的时候如何快速进行调试, 其实也属于基础设施的范畴. 思考一下, 译码查找表中有那么多指令, 每一条指令又通过若干RTL指令实现, 如果其中实现有误, 我们该如何发现呢?

直觉上这貌似不是一件容易的事情, 不过让我们来讨论一下其中的缘由. 假设我们不小心把译码查找表中的某一条指令的译码函数填错了, NEMU执行到这一条指令的时候, 就会使用错误的译码函数进行译码, 从而导致执行函数拿到了错误的源操作数, 或者是将正确的结果写入了错误的目的操作数. 这样, NEMU执行这条指令的结果就违反了它原来的语义, 接下来就会导致跟这条指令有依赖关系的其它指令也无法正确地执行. 最终, 我们就会看到客户程序访问内存越界, 陷入死循环, 或者HIT BAD TRAP, 甚至是NEMU触发了段错误.

#### 调试的工具与原理

我们可以从上面的这个例子中抽象出一些软件工程相关的概念:

- Fault: 实现错误的代码, 例如填写了错误的译码函数
- Error: 程序执行时不符合预期的状态, 例如客户程序的指令没有被正确地执行
- Failure: 能直接观测到的错误, 例如HIT BAD TRAP, 段错误等

调试其实就是从观测到的failure一步一步回溯寻找fault的过程, 找到了fault之后, 我们就很快知道应该如何修改错误的代码了. 但从上面的例子也可以看出, 调试之所以不容易, 恰恰是因为:

- fault不一定马上触发error
- 触发了error也不一定马上转变成可观测的failure
- error会像滚雪球一般越积越多, 当我们观测到failure的时候, 其实已经距离fault非常遥远了

理解了这些原因之后, 我们就可以制定相应的策略了:

- 尽可能把fault转变成error. 这其实就是测试做的事情, 所以`nexus-am/tests/`目录下提供了各种各样的测试用例. 但并不是有了测试用例就能把所有fault都转变成error了, 因为这取决于测试的覆盖度. 要设计出一套全覆盖的测试并不是一件简单的事情, 越是复杂的系统, 全覆盖的测试就越难设计. 至少, 框架代码中提供的测试用例的覆盖度还是很有限的. 但是, 如何提高测试的覆盖度, 是学术界一直以来都在关注的问题.
- 尽早观测到error的存在. 观测到error的时机直接决定了调试的难度: 如果等到触发failure的时候才发现error的存在, 调试就会比较困难; 但如果能在error刚刚触发的时候就观测到它, 调试难度也就大大降低了. 事实上, 你已经见识过一些有用的工具了:
  - `-Wall`, `-Werror`: 在编译时刻把潜在的fault直接转变成failure. 这种工具的作用很有限, 只能寻找一些在编译时刻也觉得可疑的fault, 例如`if (p = NULL)`, 但也是代价最低的.
  - `assert()`: 在运行时刻把error直接转变成failure. `assert()`是一个很简单却又非常强大的工具, 只要在代码中定义好程序应该满足的特征, 就一定能在运行时刻将不满足这些特征的error拦截下来. 例如链表的实现, 我们只需要在代码中插入一些很简单的`assert()`(例如指针不为空), 就能够几乎告别段错误. 事实上, 客户程序之所以会HIT BAD TRAP, 其实也是因为违背了我们设置的`nemu_assert()`. 但是, 编写这些`assert()`其实需要我们对程序的行为有一定的了解, 同时在程序特征不易表达的时候, `assert()`的作用也较为有限.
  - `printf()`: 通过输出的方式观察潜在的error. 这是用于回溯fault时最常用的工具, 用于观测程序中的变量是否进入了错误的状态. 在NEMU中我们提供了输出更多调试信息的宏`Log()`, 它实际上封装了`printf()`的功能. 但由于`printf()`需要根据输出的结果人工判断是否正确, 在便利程度上相对于`assert()`的自动判断就逊色了不少.
  - GDB: 随时随地观测程序的任何状态. 调试器是最强大的工具, 但你需要在程序行为的茫茫大海中观测那些可疑的状态, 因此使用起来的代价也是最大的.

根据上面的分析, 我们就可以总结出一些调试的建议:

- 总是使用`-Wall`和`-Werror`
- 尽可能多地在代码中插入`assert()`
- `assert()`无法捕捉到error时, 通过`printf()`输出可疑的变量, 期望能观测到error
- `printf()`不易观测error时, 通过GDB理解程序的细致行为

#### Differential Testing

如果你在程序设计课上听说过上述这些建议, 相信你几乎不会遇到过运行时错误. 然而回过头来看上文提到的指令实现的bug, 我们会发现, 这些工具还是不够用: 我们很难通过`assert()`来表达指令的正确行为来进行自动检查, 而`printf()`和GDB实际上并没有缩短error和failure的距离.

如果有一种方法能够表达指令的正确行为, 我们就可以基于这种方法来进行类似`assert()`的检查了. 那么, 究竟什么地方表达了指令的正确行为呢? 最直接的, 当然就是i386手册了, 但是我们恰恰就是根据i386手册中的指令行为来在NEMU中实现指令的, 同一套方法不能既用于实现也用于检查. 如果有一个i386手册的参考实现就好了. 嘿! 我们用的真机不就是根据i386手册实现出来的吗? 我们让在NEMU中执行的每条指令也在真机中执行一次, 然后对比NEMU和真机的状态, 如果NEMU和真机的状态不一致, 我们就捕捉到error了!

这实际上是一种非常奏效的测试方法, 在软件测试领域称为[differential testing](https://en.wikipedia.org/wiki/Differential_testing). 我们刚才提到了"状态", 那"状态"具体指的是什么呢? 我们在PA1中已经认识到, 计算机就是一个数字电路. 那么, "计算机的状态"就恰恰是那些时序逻辑部件的状态, 也就是寄存器和内存的值. 其实仔细思考一下, 计算机执行指令, 就是修改这些时序逻辑部件的状态的过程. 要检查指令的实现是否正确, 只要检查这些时序逻辑部件中的值是否一致就可以了! Differential testing可以非常及时地捕捉到error, 第一次发现NEMU的寄存器或内存的值与真机不一样的时候, 就是因为当时执行的指令实现有误导致的. 这时候其实离error非常接近, 防止了error进一步传播的同时, 要回溯找到fault也容易得多.

多么美妙的功能啊! 背后还蕴含着计算机本质的深刻原理! 但很遗憾, 不要忘记了, 真机上是运行了操作系统GNU/Linux的, 而NEMU中的测试程序是运行在AM上的. 就如前文所说, 它们提供的运行时环境是不一样的, 我们无法在GNU/Linux中运行基于`x86-nemu`的AM程序. 所以, 我们需要的不仅是一个i386手册的正确实现, 而且需要在上面能正确运行基于`x86-nemu`的AM程序.

事实上, QEMU就是一个不错的参考实现. 它是一个虚拟出来的完整的x86计算机系统, 而NEMU的目标只是虚拟出x86的一个子集, 能在NEMU上运行的程序, 自然也能在QEMU上运行. 因此, 为了通过differential testing的方法测试NEMU实现的正确性, 我们让NEMU和QEMU逐条指令地执行同一个客户程序. 双方每执行完一条指令, 就检查各自的寄存器和内存的状态, 如果发现状态不一致, 就马上报告错误, 停止客户程序的执行.

NEMU的框架代码已经准备好相应的功能了, 在`nemu/include/common.h`中定义宏`DIFF_TEST`之后, 重新编译NEMU后运行, 你会发现NEMU多输出了`Connect to QEMU successfully`的信息. 定义了宏`DIFF_TEST`之后, monitor会多进行以下初始化工作, 你不需要了解这些工作的具体细节, 只需要知道这是在为了让QEMU进入一个和NEMU同等的状态就可以了.

- 调用`init_difftest()`函数(在`nemu/src/monitor/diff-test/diff-test.c`中定义)来启动QEMU. 需要注意的是, 框架代码让QEMU运行在后台, 因此你将看不到QEMU的任何输出.
- 在`load_img()`的最后将客户程序拷贝一份副本到QEMU模拟的内存中.
- 在`restart()`中调用`init_qemu_reg()`函数(在`nemu/src/monitor/diff-test/diff-test.c`中定义), 来把QEMU的通用寄存器设置成和NEMU一样.

进行了上述初始化工作之后, QEMU和NEMU就处于相同的状态了. 接下来就要进行逐条指令执行后的状态对比了, 实现这一功能的是`difftest_step()`函数(在`nemu/src/monitor/diff-test/diff-test.c`中定义). 它会在`exec_wrapper()`的最后被调用, 在NEMU中执行完一条指令后, 就在`difftest_step()`中让QEMU执行相同的指令, 然后读出QEMU中的寄存器. 你需要添加相应的代码, 把NEMU的8个通用寄存器和eip与从QEMU中读出的寄存器的值进行比较, 如果发现值不一样, 就输出相应的提示信息, 并将`diff`标志设置为`true`. 在`difftest_step()`的最后, 如果检测到`diff`标志为`true`, 就停止客户程序的运行.

{% panel style="success", title="实现differential testing" %}

在`difftest_step()`中添加相应的代码, 实现differential testing的核心功能. 实现正确后, 你将会得到一款无比强大的测试工具. 

体会到differential testing的强大之后, 不妨思考一下: 作为一种基础设施, differential testing能帮助你节省多少调试的时间呢?

{% endpanel %}

咦? 我们不需要对内存的状态进行比较吗?事实上, NEMU是通过一套GDB协议与QEMU通信来获取QEMU的状态的,但是通过这一协议还是不好获取指令修改的内存位置, 而对比整个内存又会带来很大的开销,所以我们就不对内存的状态进行比较了.事实上, NEMU中的简化实现也会导致某些寄存器的状态与QEMU的结果不一致, 例如EFLAGS,NEMU只实现了EFLAGS中的少量标志位, 同时也简化了某些指令对EFLAGS的更新.另外, 一些特殊的系统寄存器也没有完整实现.因此, 我们实现的differential testing并不是完整地对比QEMU和NEMU的状态,但是不管是内存还是标志位, 只要客户程序的一条指令修改了它们,在不久的将来肯定也会再次用到它们, 到时候一样能检测出状态的不同.同时框架中也准备了`is_skip_nemu`和`is_skip_qemu`这两个变量,用于跳过少量不易进行对比的指令.因此, 我们其实牺牲了一些比较的精度, 来换取性能的提升,但即使这样, 由于differential testing需要与QEMU进行通信, 这还是会把NEMU的运行速度拉低上百倍.因此除非是在进行调试, 否则不建议打开differential testing的功能来运行NEMU.

## 程序, 运行时环境与AM

 

### 现代指令系统

 

我们已经成功在TRM上运行`dummy`程序了, 然而这个程序什么都没做就结束了, 一点也不过瘾啊. 为了让NEMU支持大部分程序的运行, 你还需要实现更多的指令:

- Data Movement Instructions: ~~`mov`~~, `push`, `pop`, `leave`, `cltd`(在i386手册中为`cdq`), ~~`movsx`, `movzx`~~
- Binary Arithmetic Instructions: `add`, `inc`, `sub`, `dec`, `cmp`, `neg`, ~~`adc`, `sbb`, `mul`, `imul`, `div`, `idiv`~~
- Logical Instructions: `not`, `and`, `or`, `xor`, `sal(shl)`, `shr`, `sar`, ~~`setcc`~~, `test`
- Control Transfer Instructions: ~~`jmp`, `jcc`~~, `call`, `ret`
- Miscellaneous Instructions: ~~`lea`, `nop`~~

框架代码已经实现了上述删除线标记的指令, 但并没有填写`opcode_table`. 此外, 某些需要更新EFLAGS的指令并没有完全实现好(框架代码中已经插入了`TODO()`作为提示), 你还需要编写相应的功能.

### 运行时环境与AM

 

但并不是有了足够的指令就能运行更多的程序. 我们之前提到"并不是每一个程序都可以在NEMU中运行", 现在我们来解释一下背后的缘由.

从直觉上来看, 让TRM来支撑一个功能齐全的操作系统的运行还是比较勉强的. 这给我们的感觉就是, 计算机也有一定的"功能强弱"之分, 计算机越"强大", 就能跑越复杂的程序. 换句话说, 程序的运行其实是对计算机的功能有需求的. 在你运行Hello World程序时, 你敲入一条命令(或者点击一下鼠标), 程序就成功运行了, 但这背后其实隐藏着操作系统开发者和库函数开发者的无数汗水. 一个事实是, 应用程序的运行都需要[运行时环境](http://en.wikipedia.org/wiki/Runtime_system)的支持, 包括加载, 销毁程序, 以及提供程序运行时的各种动态链接库(你经常使用的库函数就是运行时环境提供的)等. 为了让客户程序在NEMU中运行, 现在轮到你来提供相应的运行时环境的支持了. 不用担心, 由于NEMU目前的功能并不完善, 我们必定无法向用户程序提供GNU/Linux般的运行时环境.

我们先来讨论一下程序执行究竟需要些什么.

1. 程序需要有地方存放代码和数据, 于是需要内存
2. 程序需要执行, 于是需要CPU以及指令集
3. 对于需要运行结束的程序, 需要有一种结束运行的方法

事实上, 可以在TRM上运行的程序都对计算机有类似的需求. 我们把这些计算机相关的需求抽象成统一的API提供给程序, 这样程序就不需要关心计算机硬件相关的细节了. 这正是AM(Abstract machine)项目的意义所在.

{% panel style="warning", title="什么是AM?" %}

你或许会觉得NEMU与AM的关系有点模糊不清, 让我们还是来看ATM机的例子.

说起ATM机, 你脑海里一定会想起一个可以存款, 取款, 查询余额, 转账的机器. 我们不妨把你脑海里的这个机器的模型称为抽象ATM机. 从用户的角度来说, 用户对ATM机的功能是有期望的: 要能存款, 取款, 查询余额, 转账.

从银行的角度来说, 不同银行的ATM机千差万别: 存款的加密方式, 交易时使用的自定义通信协议, 余额在银行系统里面的表示和组织方式... 不同银行的ATM机之间存在这么多细节上的差异, 怎么样才能让用户方便地使用ATM机呢? 那就是, 为不同银行的ATM机分别实现上文提到的抽象ATM机的功能: 只要ATM机实现了存款, 取款和查询余额的这组统一的功能, 和用户对抽象ATM机的认识匹配上, 用户就可以方便地使用这台ATM机, 而不必关心ATM机的上述细节. 

在NEMU和AM的关系中, 程序就像是用户, AM就像是抽象ATM机, 我们实现NEMU这个计算机就像是造一台新的(虚拟的)ATM机, 也就像我们在PA1中提到的, 写一个支付宝APP. 同样的道理, 程序对计算机的功能是有期望的: 要能计算, 输入输出... 这些功能的期望组成了一台抽象计算机AM, 它刻画了一台真实计算机应该具备的功能. 但不同计算机的硬件配置各不相同, ISA也千差万别, 怎么样才能让程序方便地运行呢? 那就是, 为不同的计算机分别实现AM的功能: 只要计算机实现了AM定义的一组统一的API, 就能和程序对计算机的功能期望匹配上, 程序就可以方便地在计算机上运行, 而不必关心计算机的底层细节.

------

 有兴趣折腾的同学还可以来理解一下真机, NEMU和AM这三者的关系. 我们会发现, 无论是真实的ATM机还是支付宝APP, 都符合我们对的抽象ATM机的认知: 它们都能存款, 取款, 查询余额, 转账. 也正因为如此, 支付宝APP刚推出的时候, 我们才能很容易上手: 虽然支付宝APP是个虚拟的ATM机, 但我们还是可以很容易根据我们对抽象ATM机的认知来使用它.

回到NEMU的例子中来, 我们还是用ATM机的例子来比喻: 真机就像是一台真实的ATM机, NEMU这个虚拟机就像是一个支付宝APP, AM还是我们概念上的抽象ATM机. 只要一台机器实现了AM的功能(能计算, 能输出输入...), 程序都可以在上面运行, 不必关心这台机器是真实的, 还是用程序虚拟出来的.

用一句话来总结这三者的关系:  **AM在概念上定义了一台抽象计算机, 它从运行程序的视角刻画了一台计算机应该具备的功能, 而真机和NEMU都是这台抽象计算机的具体实现, 只是真机是通过物理上存在的数字电路来实现, NEMU是通过程序来实现.**

如果你对面向对象程序设计有一些初步的了解, 解释起来就更简单了:

> AM是个抽象类, 真机和虚拟机是由AM这个抽象类派生出来的两个子类, 而x86真机和NEMU则分别是这两个子类的实例化.

{% endpanel %}

AM作为一个计算机的抽象模型, 可以将一个现代计算机从逻辑上划分成以下模块

```
AM = TRM + IOE + ASYE + PTE + MPE
```

- RM(Turing Machine) - 图灵机, 为计算机提供基本的计算能力
- IOE(I/O Extension) - 输入输出扩展, 为计算机提供输出输入的能力
- ASYE(Asynchronous Extension) - 异步处理扩展, 为计算机提供处理中断异常的能力
- PTE(Protection Extension) - 保护扩展, 为计算机提供存储保护的能力
- MPE(Multi-Processor Extension) - 多处理器扩展, 为计算机提供多处理器通信的能力 (MPE超出了ICS课程的范围, 在PA中不会涉及)

不同程序对计算机的功能需求也不完全一样, 例如只进行纯粹计算任务的程序在TRM上就可以运行; 要运行小游戏, 仅仅是TRM就不够了, 因为小游戏还需要和用户进行交互, 因此还需要IOE; 要运行一个现代操作系统, 还要在此基础上加入ASYE和PTE. 我们知道ISA是计算机系统中的软硬件接口, 而从上述AM的模块划分可以看出, AM描述的恰恰就是ISA本身, 它是不同ISA的抽象.

感谢AM项目的诞生, 让NEMU和程序的界线更加泾渭分明, 同时使得PA的流程更加明确:

```
(在NEMU中)实现硬件功能 -> (在AM中)提供软件抽象 -> (在APP层)运行程序
(在NEMU中)实现更强大的硬件功能 -> (在AM中)提供更丰富的软件抽象 -> (在APP层)运行更复杂的程序
```

这个流程其实与PA1中开天辟地的故事遥相呼应: 先驱希望创造一个计算机的世界, 并赋予它执行程序的使命. 亲自搭建NEMU(硬件)和AM(软件)之间的桥梁来支撑程序的运行, 是"理解程序如何在计算机上运行"这一终极目标的不二选择.

### RTFSC(3)

 

我们来简单介绍一下AM项目的代码. 代码中`nexus-am`目录下的源文件组织如下(部分目录下的文件并未列出):

 

```
nexus-am
├── am                               # AM相关
│   ├── am.h
│   ├── arch                         # 不同体系结构-平台的AM实现
│   │   ├── native
│   │   └── x86-nemu                 # x86-nemu的AM实现
│   │       ├── img                  # 构建/运行二进制文件/镜像的脚本
│   │       │   ├── boot
│   │       │   │   ├── Makefile
│   │       │   │   └── start.S      # 程序入口
│   │       │   ├── build            # 构建脚本
│   │       │   ├── loader.ld        # 链接脚本
│   │       │   └── run              # 运行脚本
│   │       ├── include
│   │       ├── README.md
│   │       └── src
│   │           ├── asye.c           # ASYE
│   │           ├── ioe.c            # IOE
│   │           ├── pte.c            # PTE
│   │           ├── trap.S
│   │           └── trm.c            # TRM
│   └── Makefile
├── apps                             # 直接运行在AM上的应用
├── libs                             # 可以直接运行在AM上的库
├── Makefile
├── Makefile.app
├── Makefile.check
├── Makefile.compile
├── Makefile.lib
├── README.md
├── SPEC.md                          # AM接口规范说明
└── tests                            # 直接运行在AM上的测试
```

整个AM项目分为三大部分:

- `nexus-am/am` - 不同计算机架构的AM实现, 在PA中我们只需要关注`nexus-am/am/arch/x86-nemu`即可
- `nexus-am/tests`和`nexus-am/apps` - 一些功能测试和直接运行AM上的应用程序
- `nexus-am/libs` - 一些体系结构无关的, 可以直接运行在AM上的库, 方便应用程序的开发

在让NEMU运行客户程序之前, 我们需要将客户程序的代码编译成可执行文件. 需要说明的是, 我们不能使用gcc的默认选项直接编译, 因为默认选项会根据GNU/Linux的运行时环境将代码编译成运行在GNU/Linux下的可执行文件. 但此时的NEMU并不能为客户程序提供GNU/Linux的运行时环境, 在NEMU中运行上述可执行文件会产生错误, 因此我们不能使用gcc的默认选项来编译用户程序.

解决这个问题的方法是[交叉编译](http://en.wikipedia.org/wiki/Cross_compiler), 我们需要在GNU/Linux下根据AM的运行时环境编译出能够在NEMU中运行的可执行文件. 为了不让链接器ld使用默认的方式链接, 我们还需要提供描述AM运行时环境的链接脚本. AM的框架代码已经把相应的配置准备好了:

- gcc将AM实现的源文件编译成目标文件, 然后通过ar将这些目标文件打包成一个归档文件作为一个库, 把不同计算机架构的AM实现通过库的方式提供给程序

- gcc把在AM上运行的应用程序源文件编译成目标文件

- 必要的时候通过gcc和ar把程序依赖的运行库也打包成归档文件

- 执行脚本文件```nexus-am/am/arch/x86-nemu/img/build```, 在脚本文件中

  - 将程序入口`nexus-am/am/arch/x86-nemu/img/boot/start.S`编译成目标文件
  - 最后让ld根据链接脚本`nexus-am/am/arch/x86-nemu/img/loader.ld`, 将上述目标文件和归档文件链接成可执行文件 

根据这一链接脚本的指示, 可执行程序重定位后的节从`0x100000`开始, 首先是`.text`节, 其中又以`nexus-am/am/arch/x86-nemu/img/boot/start.o`中自定义的`entry`节开始, 然后接下来是其它目标文件的`.text`节. 这样, 可执行程序的`0x100000`处总是放置`nexus-am/am/arch/x86-nemu/img/boot/start.S`的代码, 而不是其它代码, 保证客户程序总能从`0x100000`开始正确执行. 链接脚本也定义了其它节(包括`.rodata`, `.data`, `.bss`)的链接顺序, 还定义了一些关于位置信息的符号, 包括每个节的末尾, 栈顶位置, 堆区的起始和末尾.

我们对编译得到的可执行文件的行为进行简单的梳理:

1. 第一条指令从`nexus-am/am/arch/x86-nemu/img/boot/start.S`开始, 设置好栈顶之后就跳转到`nexus-am/am/arch/x86-nemu/src/trm.c`的`_trm_init()`函数处执行.
2. 在`_trm_init()`中调用`main()`函数执行程序的主体功能.
3. 从`main()`函数返回后, 调用`_halt()`结束运行.

阅读`nexus-am/am/arch/x86-nemu/src/trm.c`中的代码, 你会发现只需要实现很少的API就可以支撑起程序在TRM上运行了:

- `_Area _heap`结构用于指示堆区的起始和末尾
- `void _putc(char ch)`用于输出一个字符
- `void _halt(int code)`用于结束程序的运行
- `void _trm_init()`用于进行TRM相关的初始化工作

这是因为, TRM所需要的指令集和内存已经被编译器考虑进去了: 编译器认为, 硬件需要提供具体的指令集实现和可用的内存, 编译生成的程序里面只需要包含"使用的指令"和"程序的内存映象"这两方面的信息, 程序就可以在硬件上运行了, 所以我们不需要在`trm.c`里面提供"使用指令集"和"使用内存"的API. 关于AM定义的API, 可以阅读`nexus-am/README.md`和`nexus-am/SPEC.md`.

{% panel style="success", title="堆和栈在哪里?" %}

我们知道代码和数据都在可执行文件里面, 但却没有提到堆(heap)和栈(stack).为什么堆和栈的内容没有放入可执行文件里面?那程序运行时刻用到的堆和栈又是怎么来的?AM的代码是否能给你带来一些启发?

{% endpanel %}

把`_putc()`作为TRM的API是一个很有趣的考虑, 我们在不久的将来再讨论它, 目前我们暂不打算运行需要调用`_putc()`的程序.

最后来看看`_halt()`. `_halt()`里面是一条[内联汇编](http://www.ibiblio.org/gferg/ldp/GCC-Inline-Assembly-HOWTO.html)语句, 内联汇编语句允许我们在C代码中嵌入汇编语句. 这条指令和我们常见的汇编指令不一样(例如`movl $1, %eax`), 它是直接通过指令的编码给出的, 它只有一个字节, 就是`0xd6`. 如果你在`nemu/src/cpu/exec/exec.c`中查看`opcode_table`, 你会发现, 这条指令正是那条特殊的`nemu_trap`! 这其实也说明了为什么要通过编码来给出这条指令, 如果你使用以下方式来给出指令, 汇编器将会报错:

```c
asm volatile("nemu_trap" : : "a" (0))
```

因为这条特殊的指令是我们人为添加的, 标准的汇编器并不能识别它. 如果你查看objdump的反汇编结果, 你会看到`nemu_trap`指令被标识为`(bad)`, 原因是类似的: objdump并不能识别我们人为添加的`nemu_trap`指令. `"a"(0)`表示在执行内联汇编语句给出的汇编代码之前, 先将`0`读入`%eax`寄存器. 这样, 这段汇编代码的功能就和`nemu/src/cpu/exec/special.c`中的helper函数`nemu_trap()`对应起来了. 此外, `volatile`是C语言的一个关键字, 如果你想了解关于`volatile`的更多信息, 请查阅相关资料.

### 运行更多的程序

未测试代码永远是错的, 你需要足够多的测试用例来测试你的NEMU. 我们在`nexus-am/tests/cputest`目录下准备了一些测试用例. 首先我们让AM项目上的程序默认编译到`x86-nemu`的AM中:

```diff
--- nexus-am/Makefile.check
+++ nexus-am/Makefile.check
@@ -7,2 +7,2 @@
-ARCH ?= native
+ARCH ?= x86-nemu
 ARCH = $(shell ls $(AM_HOME)/am/arch/)
```

然后在`nexus-am/tests/cputest/`目录下执行

```bash
make ALL=xxx run
```

其中`xxx`为测试用例的名称(不包含`.c`后缀).

上述`make run`的命令最终会调用`nexus-am/am/arch/x86-nemu/img/run`来启动NEMU. 为了使用GDB来调试NEMU, 你需要修改这一`run`脚本的内容:

```diff
--- nexus-am/am/arch/x86-nemu/img/run
+++ nexus-am/am/arch/x86-nemu/img/run
@@ -3,1 +3,1 @@
-make -C $NEMU_HOME run ARGS="-l `dirname $1`/nemu-log.txt $1.bin"
+make -C $NEMU_HOME gdb ARGS="-l `dirname $1`/nemu-log.txt $1.bin"
```

然后再执行上述`make run`的命令即可. 无需GDB调试时, 可将上述`run`脚本改回来.

{% panel style="success", title="实现更多的指令" %}

你需要实现上文中提到的更多指令, 以通过上述测试用例.

你可以自由选择按照什么顺序来实现指令. 经过PA1的训练之后, 你应该不会实现所有指令之后才进行测试了. 要养成尽早做测试的好习惯, 一般原则都是"实现尽可能少的指令来进行下一次的测试". 你不需要实现所有指令的所有形式, 只需要通过这些测试即可. 如果将来仍然遇到了未实现的指令, 就到时候再实现它们.

需要注意的是, `push imm8`指令需要对立即数进行符号扩展, 这一点在i386手册中并没有明确说明. 在[IA-32手册](http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-manual-325462.pdf)中关于`push`指令有如下说明:

> If the source operand is an immediate and its size is less than the operand size, a sign-extended value is pushed on the stack.

由于部分测试用例需要实现较多指令, 建议按照以下顺序进行测试:

1. 其它
2. string
3. hello-str

{% endpanel %}



## 一键回归测试

在实现指令的过程中, 你不仅需要调试, 你还需要逐个测试用例地运行. 但在指令实现正确之后, 是不是意味着可以和这些测试用例说再见呢? 显然不是. 以后你还需要在NEMU中加入新的功能, 为了保证加入的新功能没有影响到已有功能的实现, 你还需要重新运行这些测试用例. 在软件测试中, 这个过程称为[回归测试](https://en.wikipedia.org/wiki/Regression_testing).

既然将来还要重复运行这些测试用例, 而手动重新运行每一个测试显然是一种效率低下的做法. 为了提高效率, 我们提供了一个用于一键回归测试的脚本. 在`nemu/`目录下运行

```bash
bash runall.sh
```

来自动批量运行`nexus-am/tests/cputest/`中的所有测试, 并报告每个测试用例的运行结果. 如果一个测试用例运行失败, 脚本将会保留相应的日志文件; 当使用脚本通过这个测试用例的时候, 日志文件将会被移除.

{% panel style="success", title="NEMU的本质" %}

你已经知道, NEMU是一个用来执行其它程序的程序. 在可计算理论中, 这种程序有一个专门的名词, 叫通用程序(Universal Program), 它的通俗含义是: 其它程序能做的事情, 它也能做. 通用程序的存在性有专门的证明, 我们在这里不做深究, 但是, 我们可以写出NEMU, 可以用Docker/虚拟机做实验, 乃至我们可以在计算机上做各种各样的事情, 其背后都蕴含着通用程序的思想: NEMU和各种模拟器只不过是通用程序的实例化, 我们也可以毫不夸张地说, 计算机就是一个通用程序的实体化. 通用程序的存在性为计算机的出现奠定了理论基础, 是可计算理论中一个极其重要的结论, 如果通用程序的存在性得不到证明, 我们就没办法放心地使用计算机, 同时也不能义正辞严地说"机器永远是对的".

我们编写的NEMU最终会被编译成x86机器代码, 用x86指令来模拟x86程序的执行. 事实上在30多年前(1983年), [Martin Davis教授](http://en.wikipedia.org/wiki/Martin_Davis) 就在他出版的"Computability, complexity, and languages: fundamentals of theoretical computer science"一书中 提出了一种仅有三种指令的程序设计语言L语言, 并且证明了L语言和其它所有编程语言的计算能力等价. L语言中的三种指令分别是:

```
V = V + 1
V = V - 1
IF V != 0 GOTO LABEL
```

用x86指令来描述, 就是`inc`, `dec`和`jne`三条指令. 假设除了输入变量之外, 其它变量的初值都是0, 并且假设程序执行到最后一条指令就结束, 你可以仅用这三种指令写一个计算两个正整数相加的程序吗? 试试下面这个小题目：

```
    # Assume a = 0, x and y are initialized with some positive integers.
    # Other temporary variables are initialized with 0.
    # Let "jne" carries a variable: jne v, label.
    # It means "jump to label if v != 0".
    # Compute a = x + y used only these three instructions: inc, dec, jnz.
    # No other instructions can be used.
    # The result should be stored in variable "a".
    # Have a try?
```



令人更惊讶的是, Martin Davis教授还证明了, 在不考虑物理限制的情况下(认为内存容量无限多, 每一个内存单元都可以存放任意大的数), 用L语言也可以编写出一个和NEMU类似的通用程序! 而且这个用L语言编写的通用程序的框架, 竟然还和NEMU中的`cpu_exec()`函数如出一辙: 取指, 译码, 执行... 这其实并不是巧合, 而是[模拟(Simulation)](http://en.wikipedia.org/wiki/Simulation#Computer_science)在计算机科学中的应用.

早在Martin Davis教授提出L语言之前, 科学家们就已经在探索什么问题是可以计算的了. 回溯到19世纪30年代, 为了试图回答这个问题, 不同的科学家提出并研究了不同的计算模型, 包括[Gödel](http://en.wikipedia.org/wiki/Godel), [Herbrand](http://en.wikipedia.org/wiki/Jacques_Herbrand)和[Kleen](http://en.wikipedia.org/wiki/Stephen_Cole_Kleene)研究的[递归函数](http://en.wikipedia.org/wiki/%CE%9C-recursive_function), [Church](http://en.wikipedia.org/wiki/Alonzo_Church)提出的[λ-演算](http://en.wikipedia.org/wiki/Lambda_calculus), [Turing](http://en.wikipedia.org/wiki/Alan_Turing)提出的[图灵机](http://en.wikipedia.org/wiki/Turing_machine), 后来发现这些模型在计算能力上都是等价的; 到了40年代, 计算机就被制造出来了. 后来甚至还有人证明了, 如果使用无穷多个算盘拼接起来进行计算, 其计算能力和图灵机等价! 我们可以从中得出一个推论, 通用程序在不同的计算模型中有不同的表现形式. NEMU作为一个通用程序, 在19世纪30年代有着非凡的意义. 如果你能在80年前设计出NEMU, 说不定"图灵奖"就要用你的名字来命名了. [计算的极限](http://t.cn/R7QCHA4)这一篇科普文章叙述了可计算理论的发展过程, 我们强烈建议你阅读它, 体会人类的文明(当然一些数学功底还是需要的). 如果你对可计算理论感兴趣, 可以选修宋方敏老师的计算理论导引课程.

把思绪回归到PA中, 通用程序的性质告诉我们, NEMU的潜力是无穷的. 为了创造出一个缤纷多彩的世界, 你觉得NEMU还缺少些什么呢?

{% endpanel %}

{% panel style="success", title="捕捉死循环(有点难度)" %}

NEMU除了作为模拟器之外, 还具有简单的调试功能, 可以设置断点, 查看程序状态. 如果让你为NEMU添加如下功能

> 当用户程序陷入死循环时, 让用户程序暂停下来, 并输出相应的提示信息

你觉得应该如何实现? 如果你感到疑惑, 在互联网上搜索相关信息.

{% endpanel %}



{% panel style="success", title="温馨提示" %}

PA2阶段2到此结束. 

{% endpanel %}